#!/usr/bin/env python3
"""
Comprehensive dataset downloader for collision parts prediction training.
Downloads Stanford Cars and vehicle damage datasets.
"""

import os
import requests
import tarfile
import zipfile
from pathlib import Path
from tqdm import tqdm
import json

def download_file(url: str, destination: Path, description: str = ""):
    """Download file with progress bar."""
    try:
        response = requests.get(url, stream=True)
        if response.status_code != 200:
            print(f"‚ùå Failed to download {description}: HTTP {response.status_code}")
            return False
            
        total_size = int(response.headers.get('content-length', 0))
        
        with open(destination, 'wb') as file, tqdm(
            desc=description,
            total=total_size,
            unit='B',
            unit_scale=True,
            unit_divisor=1024,
        ) as pbar:
            for chunk in response.iter_content(chunk_size=8192):
                size = file.write(chunk)
                pbar.update(size)
        
        print(f"‚úÖ Downloaded {description} ({destination.stat().st_size / 1024 / 1024:.1f} MB)")
        return True
        
    except Exception as e:
        print(f"‚ùå Error downloading {description}: {e}")
        return False

def extract_archive(archive_path: Path, extract_to: Path):
    """Extract tar.gz or zip archive."""
    try:
        if archive_path.suffix.lower() in ['.tgz', '.gz']:
            with tarfile.open(archive_path, 'r:gz') as tar:
                tar.extractall(extract_to)
        elif archive_path.suffix.lower() == '.zip':
            with zipfile.ZipFile(archive_path, 'r') as zip_ref:
                zip_ref.extractall(extract_to)
        
        print(f"‚úÖ Extracted {archive_path.name}")
        return True
        
    except Exception as e:
        print(f"‚ùå Error extracting {archive_path}: {e}")
        return False

def download_stanford_cars():
    """Download Stanford Cars dataset from alternative sources."""
    print("üöó Downloading Stanford Cars Dataset...")
    
    cars_dir = Path("data/raw/stanford_cars")
    cars_dir.mkdir(parents=True, exist_ok=True)
    
    # Try alternative URLs
    alternative_urls = [
        {
            'name': 'Stanford Cars (Mirror 1)',
            'url': 'https://github.com/pytorch/vision/releases/download/v0.8.0/cars_train.tgz',
            'file': 'cars_train.tgz'
        },
        {
            'name': 'Stanford Cars (Academic Mirror)', 
            'url': 'https://www.vision.caltech.edu/datasets/cars_overhead/cars_train.tgz',
            'file': 'cars_train.tgz'
        }
    ]
    
    success = False
    for source in alternative_urls:
        print(f"üîÑ Trying {source['name']}...")
        filepath = cars_dir / source['file']
        
        if download_file(source['url'], filepath, source['name']):
            if extract_archive(filepath, cars_dir):
                success = True
                break
    
    if not success:
        print("‚ö†Ô∏è Could not download Stanford Cars from automatic sources.")
        print("üìã Manual download instructions:")
        print("1. Visit: https://www.kaggle.com/datasets/jessicali9530/stanford-cars-dataset")
        print("2. Download cars_train.tgz and cars_test.tgz")
        print(f"3. Place files in: {cars_dir.absolute()}")
        
        # Create placeholder structure for testing
        create_sample_cars_data(cars_dir)
    
    return success

def create_sample_cars_data(cars_dir: Path):
    """Create sample car images for testing when real data isn't available."""
    print("üîß Creating sample car data for testing...")
    
    from PIL import Image
    import random
    
    # Create sample images directory
    sample_dir = cars_dir / "cars_train"
    sample_dir.mkdir(exist_ok=True)
    
    # Generate sample car images
    car_colors = ['red', 'blue', 'green', 'yellow', 'black', 'white', 'silver']
    
    for i in range(100):  # Create 100 sample images
        color = random.choice(car_colors)
        img = Image.new('RGB', (224, 224), color=color)
        img_path = sample_dir / f"car_{i:03d}.jpg"
        img.save(img_path, 'JPEG')
    
    print(f"‚úÖ Created {len(list(sample_dir.glob('*.jpg')))} sample car images")

def download_vehicle_damage_data():
    """Download or create vehicle damage dataset."""
    print("üîß Setting up Vehicle Damage Dataset...")
    
    damage_dir = Path("data/raw/vehide_images")
    damage_dir.mkdir(parents=True, exist_ok=True)
    
    # Since VEHiDe dataset requires academic access, create sample damage data
    create_sample_damage_data(damage_dir)

def create_sample_damage_data(damage_dir: Path):
    """Create sample vehicle damage data with annotations."""
    print("üîß Creating sample damage data...")
    
    from PIL import Image, ImageDraw
    import random
    
    damage_types = ['dent', 'paint_scratch', 'rust', 'crack', 'broken_glass', 
                   'bumper_damage', 'headlight_damage', 'wheel_damage', 'mirror_damage']
    
    annotations = {
        "_via_settings": {
            "ui": {"annotation_editor_height": 25, "annotation_editor_fontsize": 0.8},
            "core": {"buffer_size": 18, "filepath": {}},
            "project": {"name": "vehicle_damage"}
        },
        "_via_img_metadata": {},
        "_via_attributes": {
            "region": {
                "damage_type": {
                    "type": "dropdown",
                    "options": {damage: "" for damage in damage_types},
                    "default_options": {}
                }
            },
            "file": {}
        }
    }
    
    # Create sample damage images
    for damage_type in damage_types:
        for i in range(10):  # 10 samples per damage type
            # Create base car image
            img = Image.new('RGB', (640, 480), color='lightgray')
            draw = ImageDraw.Draw(img)
            
            # Add damage visualization
            if damage_type == 'dent':
                draw.ellipse([200, 200, 250, 230], fill='darkgray')
            elif damage_type == 'paint_scratch':
                draw.line([100, 150, 200, 180], fill='brown', width=3)
            elif damage_type == 'rust':
                draw.rectangle([300, 250, 350, 280], fill='orangered')
            elif damage_type == 'crack':
                draw.line([150, 100, 180, 140], fill='black', width=2)
            # Add more damage visualizations...
            
            filename = f"{damage_type}_{i:02d}.jpg"
            img_path = damage_dir / filename
            img.save(img_path, 'JPEG')
            
            # Add to annotations
            file_size = img_path.stat().st_size
            annotations["_via_img_metadata"][filename] = {
                "filename": filename,
                "size": file_size,
                "regions": [
                    {
                        "shape_attributes": {
                            "name": "rect",
                            "x": 150,
                            "y": 150,
                            "width": 100,
                            "height": 80
                        },
                        "region_attributes": {
                            "damage_type": damage_type
                        }
                    }
                ],
                "file_attributes": {}
            }
    
    # Save annotations
    annotations_path = Path("data/raw/vehide_annotations.json")
    with open(annotations_path, 'w') as f:
        json.dump(annotations, f, indent=2)
    
    print(f"‚úÖ Created {len(list(damage_dir.glob('*.jpg')))} sample damage images")
    print(f"‚úÖ Created annotations file: {annotations_path}")

def main():
    """Main download function."""
    print("üöÄ Starting Dataset Download Process...")
    print("="*50)
    
    # Create data directories
    Path("data/raw").mkdir(parents=True, exist_ok=True)
    Path("data/processed").mkdir(parents=True, exist_ok=True)
    
    # Download Stanford Cars
    download_stanford_cars()
    print()
    
    # Download/Create Vehicle Damage Data
    download_vehicle_damage_data()
    print()
    
    print("‚úÖ Dataset download process completed!")
    print("üìÅ Data structure:")
    print("   data/raw/stanford_cars/")
    print("   data/raw/vehide_images/")
    print("   data/raw/vehide_annotations.json")
    print()
    print("üéØ Next steps:")
    print("   1. python -m hydra main=src.data.prepare_no_damage")
    print("   2. python -m hydra main=src.data.merge_annotations") 
    print("   3. python -m hydra main=src.training.train_resnet")
    print("   4. python -m hydra main=src.training.train_yolo")

if __name__ == "__main__":
    main()